{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abZ7bOgX3tVh"
   },
   "source": [
    "# Training multiple Learner with Random Sampling\n",
    "\n",
    "**Author:** [kkahloots](https://www.linkedin.com/in/kkahloots/)<br>\n",
    "**Date created:** 2020/11/08<br>\n",
    "**Last modified:** 2020/11/08<br>\n",
    "**Description:** Performing learning as tasks by multiple learners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cy1Mc1Mf3tVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVGVWKY-3tVu"
   },
   "source": [
    "## Algorithm Setup \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180, 3)\n",
    "batch_size = 36\n",
    "n_learner=100\n",
    "n_classes=2\n",
    "validation_percentage=0.2\n",
    "sample_percentage=0.3\n",
    "valid_format = 'jpg'\n",
    "image_dir = \"data/PetImages/train\"\n",
    "holdout_dir = 'data/PetImages/holdout'\n",
    "epochs = 20 #int(1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators.from_images.file_image_generator import make_image_lists, get_generators\n",
    "from builder.learner_building import make_learner\n",
    "from tensorflow_addons.optimizers import RectifiedAdam\n",
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.binary_crossentropy\n",
    "metrics=[tf.metrics.Accuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\n",
      "\ttraining         \t (min:    0.502, max:    0.502, cur:    0.502)\n",
      "\tvalidation       \t (min:    0.428, max:    0.428, cur:    0.428)\n",
      "Loss\n",
      "\ttraining         \t (min:    7.678, max:    7.678, cur:    7.678)\n",
      "\tvalidation       \t (min:    8.818, max:    8.818, cur:    8.818)\n",
      "500/500 [==============================] - 241s 481ms/step - loss: 7.6782 - accuracy: 0.5019 - val_loss: 8.8179 - val_accuracy: 0.4283\n",
      "Epoch 2/20\n",
      "500/500 [==============================] - ETA: 0s - loss: 7.6765 - accuracy: 0.5023"
     ]
    }
   ],
   "source": [
    "for learner_id in range(n_learner):\n",
    "    imgs_list = make_image_lists(\n",
    "    image_dir=image_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format,\n",
    "    sample_pct=sample_percentage\n",
    "    )\n",
    "    \n",
    "    train_generator, validation_generator = \\\n",
    "                                    get_generators(\n",
    "                                                    images_list=imgs_list, \n",
    "                                                    image_dir=image_dir,\n",
    "                                                    holdout_dir=None,\n",
    "                                                    holdout_list=None,\n",
    "                                                    image_size=image_size, \n",
    "                                                    batch_size=batch_size, \n",
    "                                                    class_mode='binary' if n_classes==2 else 'categorical',\n",
    "                                                    rotation_range=40,\n",
    "                                                    width_shift_range=0.2,\n",
    "                                                    height_shift_range=0.2,\n",
    "                                                    shear_range=0.2,\n",
    "                                                    zoom_range=0.2,\n",
    "                                                    horizontal_flip=True,\n",
    "                                                    fill_mode='nearest',\n",
    "                                                    return_filename=False\n",
    "                                                                    )\n",
    "    \n",
    "    train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator, \n",
    "    output_types= (tf.float32, tf.float32)\n",
    "    )\n",
    "\n",
    "    val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_generator, \n",
    "    output_types= (tf.float32, tf.float32)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    learner = make_learner(model_name=f'learner{learner_id}', input_shape=image_size, num_classes=n_classes)\n",
    "    \n",
    "    es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val-loss', \n",
    "    min_delta=1e-6, \n",
    "    patience=6, \n",
    "    verbose=1, \n",
    "    restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    learner_sp = f\"experiments/{learner.name}.hdf5\"\n",
    "    ms =  tf.keras.callbacks.ModelCheckpoint(filepath=learner_sp, \n",
    "                                            verbose=1, \n",
    "                                            save_best_only=True)\n",
    "    \n",
    "\n",
    "    callbacks = [es, ms, PlotLossesKeras()]\n",
    "\n",
    "    learner.compile(\n",
    "        optimizer=RectifiedAdam(),\n",
    "        loss=loss_fn,\n",
    "        metrics=metrics\n",
    "    )\n",
    "\n",
    "    learner.fit(\n",
    "                x=train_ds, \n",
    "                epochs=epochs, \n",
    "                steps_per_epoch=500,\n",
    "                callbacks=callbacks, \n",
    "                validation_data=val_ds, \n",
    "                validation_steps=500,\n",
    "                workers=-1,\n",
    "                use_multiprocessing=True,\n",
    "                verbose=1\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T-a9YhO3tV-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_list = make_image_lists(\n",
    "    image_dir=holdout_dir, \n",
    "    validation_pct=0.0, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-1apOpM3tWA"
   },
   "source": [
    "## Evaluate the learner on training, validation and holdout dataset\n",
    "\n",
    "Note that data augmentation and dropout are inactive at inference time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = tf.keras.models.load_model(filepath=learner_sp, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_epoch=10\n",
    "momory_file = 'memory/learner_tracing.csv'\n",
    "col_names = ['filename', 'learner', 'score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from memory.memory_manager import insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_file = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert(filename= filename[0].replace('\\\\', '/'), learner=learner.name, score=loss_value.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ep in tqdm(range(eval_epoch)):\n",
    "    images, labels, filenames = next(train_generator)\n",
    "    loss_values = loss_fn(labels, learner.predict(images))\n",
    "    for filename, loss_value in zip(filenames.values(), loss_values):\n",
    "        record = {'filename': filename[0].replace('\\\\', '/'), 'learner':learner.name, 'score': loss_value.numpy()}\n",
    "        ix = 0 if pd.isnull(memory_file.index.max()) else memory_file.index.max()\n",
    "        memory_file.loc[ix+1] = record.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = '1'\n",
    "memory_file.to_csv(f'memory/learner_tracing{e}.csv', index=False, mode='a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "memory_file = pd.read_csv(filepath_or_buffer=momory_file, names=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory_file.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_score = memory_file.groupby(['filename', 'learner'])['score'].mean().to_frame().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_score[files_score['filename'] ==\"data/PetImages/train/Cat/11206.jpg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_score['score'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds2itr(ds):\n",
    "    while True:\n",
    "        try:\n",
    "            for data in ds:\n",
    "                yield data\n",
    "        except StopIteration as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take2(gen):\n",
    "    while True:\n",
    "        batch = next(gen)\n",
    "        yield batch[0], batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.Dataset.from_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: take2(train_generator), \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: take2(validation_generator), \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")\n",
    "\n",
    "holdout_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: take2(holdout_generator), \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(train_ds)\n",
    "train_loss_scores = {}\n",
    "train_loss_score = []\n",
    "for ep in tqdm(range(eval_epoch)):\n",
    "    batch = next(ds)\n",
    "    train_loss_value = loss_fn(batch[1], learner.predict(batch[0]) )\n",
    "    train_loss_score += [train_loss_value]\n",
    "train_loss_scores = {loss_fn.__name__: train_loss_score}   \n",
    "\n",
    "train_loss_scores = {k: {'min': \n",
    "                          tf.math.reduce_min([*val][0], axis=0).numpy(), \n",
    "                          'max':\n",
    "                          tf.math.reduce_max([*val][0], axis=0).numpy(), \n",
    "                          'std': \n",
    "                          tf.math.reduce_std([*val][0], axis=0).numpy(), \n",
    "                          'mean': \n",
    "                          tf.math.reduce_mean([*val][0], axis=0).numpy() } for k, val in train_loss_scores.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)\n",
    "val_loss_scores = {}\n",
    "val_loss_score = []\n",
    "for ep in tqdm(range(eval_epoch)):\n",
    "    batch = next(ds)\n",
    "    val_loss_value = loss_fn(batch[1], learner.predict(batch[0]) )\n",
    "    val_loss_score += [val_loss_value]\n",
    "val_loss_scores = {loss_fn.__name__: val_loss_score}   \n",
    "\n",
    "val_loss_scores = {k: {'min': \n",
    "                          tf.math.reduce_min([*val][0], axis=0).numpy(), \n",
    "                          'max':\n",
    "                          tf.math.reduce_max([*val][0], axis=0).numpy(), \n",
    "                          'std': \n",
    "                          tf.math.reduce_std([*val][0], axis=0).numpy(), \n",
    "                          'mean': \n",
    "                          tf.math.reduce_mean([*val][0], axis=0).numpy() } for k, val in val_loss_scores.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train loss', train_loss_scores)\n",
    "print('val loss',val_loss_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision = lambda x: 1 if x > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(train_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    train_metric_scores = {}\n",
    "    train_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        train_metric_value = metric_fn(batch[1], pred)\n",
    "        train_metric_score += [train_metric_value]\n",
    "    train_metric_scores = {metric: train_metric_score}   \n",
    "\n",
    "    train_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in train_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(train_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    val_metric_scores = {}\n",
    "    val_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        val_metric_value = metric_fn(batch[1], pred)\n",
    "        val_metric_score += [val_metric_value]\n",
    "    val_metric_scores = {metric: val_metric_score}   \n",
    "\n",
    "    val_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in val_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(val_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(holdout_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    holdout_metric_scores = {}\n",
    "    holdout_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        holdout_metric_value = metric_fn(batch[1], pred)\n",
    "        holdout_metric_score += [holdout_metric_value]\n",
    "    holdout_metric_scores = {metric: holdout_metric_score}   \n",
    "\n",
    "    holdout_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in holdout_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(holdout_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train metric', train_metric_scores)\n",
    "print('val metric',val_metric_scores)\n",
    "print('holdout metric', holdout_metric_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = tf.keras.models.load_model(filepath=learner_sp, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.layers[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Reshape(image_size)(learner.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Model(inputs=learner.inputs, outputs=[x])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(ds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((images[0].numpy()* 255.0).astype(np.uint8), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((predictions[0] * 255.0).astype(np.uint8), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reporting.ploting import plot_and_save_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_generated(images.numpy(), epoch=999, path='.', gray=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_generated( [Image.fromarray((img * 255.0).astype(np.uint8), mode='RGB') for img in predictions], epoch=999, path='.', gray=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_from_scratch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
