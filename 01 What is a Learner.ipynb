{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abZ7bOgX3tVh"
   },
   "source": [
    "# Building and Training a Learner\n",
    "\n",
    "**Author:** [kkahloots](https://www.linkedin.com/in/kkahloots/)<br>\n",
    "**Date created:** 2020/11/07<br>\n",
    "**Last modified:** 2020/11/07<br>\n",
    "**Description:** Performing learning as tasks by multiple learners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vbleiv5e3tVh"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example shows how to do image classification from scratch, starting from JPEG\n",
    "image files on disk, without leveraging pre-trained weights or a pre-made Keras\n",
    "Application model. We demonstrate the workflow on the Kaggle Cats vs Dogs binary\n",
    " classification dataset.\n",
    "\n",
    "We use the `image_dataset_from_directory` utility to generate the datasets, and\n",
    "we use Keras image preprocessing layers for image standardization and data augmentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPe3NAfa3tVi"
   },
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Cy1Mc1Mf3tVi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVGVWKY-3tVu"
   },
   "source": [
    "## Generate a `Dataset`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180, 3)\n",
    "batch_size = 36\n",
    "validation_percentage=0.3\n",
    "valid_format = 'jpg'\n",
    "image_dir = \"data/PetImages/train\"\n",
    "holdout_dir = 'data/PetImages/holdout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generators.from_images.file_image_generator import make_image_lists, get_generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'Cat'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m10573 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'Dog'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m10506 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imgs_list = make_image_lists(\n",
    "    image_dir=image_dir, \n",
    "    validation_pct=validation_percentage, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'Cat'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1175 file found\u001b[0m\n",
      "  \u001b[37mDEBUG   \u001b[0m | \u001b[37mLooking for images in 'Dog'\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32m1168 file found\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "holdout_list = make_image_lists(\n",
    "    image_dir=holdout_dir, \n",
    "    validation_pct=0.0, \n",
    "    valid_imgae_formats=valid_format\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  \u001b[32mINFO    \u001b[0m | \u001b[32mFound 21009 training files\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32mFound 70 validation files\u001b[0m\n",
      "  \u001b[32mINFO    \u001b[0m | \u001b[32mFound 2343 training files\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, holdout_generator = get_generators(\n",
    "                                                                            images_list=imgs_list, \n",
    "                                                                            image_dir=image_dir,\n",
    "                                                                            holdout_dir=holdout_dir,\n",
    "                                                                            holdout_list=holdout_list,\n",
    "                                                                            image_size=image_size, \n",
    "                                                                            batch_size=batch_size, \n",
    "                                                                            class_mode='binary',\n",
    "                                                                            rotation_range=40,\n",
    "                                                                            width_shift_range=0.2,\n",
    "                                                                            height_shift_range=0.2,\n",
    "                                                                            shear_range=0.2,\n",
    "                                                                            zoom_range=0.2,\n",
    "                                                                            horizontal_flip=True,\n",
    "                                                                            fill_mode='nearest'\n",
    "                                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: train_generator, \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: validation_generator, \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")\n",
    "\n",
    "holdout_ds = tf.data.Dataset.from_generator(\n",
    "    lambda: holdout_generator, \n",
    "    output_types= (tf.float32, tf.float32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5vGPKUix3tVu"
   },
   "outputs": [],
   "source": [
    "# from dataset_generating import prepare_generators\n",
    "# train_ds, val_ds, holdout_ds = prepare_generators(image_dir=image_dir, \n",
    "#                                                  batch_size=batch_size, \n",
    "#                                                  image_size=image_size,\n",
    "#                                                  holdout_dir=holdout_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eIZ3VWA3tV7"
   },
   "source": [
    "## Build a model\n",
    "\n",
    "We'll build a small version of the Xception network. We haven't particularly tried to\n",
    "optimize the architecture; if you want to do a systematic search for the best model\n",
    " configuration, consider using\n",
    "[Keras Tuner](https://github.com/keras-team/keras-tuner).\n",
    "\n",
    "Note that:\n",
    "\n",
    "- We start the model with the `data_augmentation` preprocessor, followed by a\n",
    " `Rescaling` layer.\n",
    "- We include a `Dropout` layer before the final classification layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from builder.learner_building import make_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"example_learner\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 180, 180, 3)]     0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 180, 180, 3)       12        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 97200)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 97201     \n",
      "=================================================================\n",
      "Total params: 97,213\n",
      "Trainable params: 97,213\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "learner = make_learner(model_name='example_learner', input_shape=image_size, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAGVCAYAAADQcqd/AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3db2gb+Z0/8Pdsku2SPrCb7dlN0jo9WBLS7dVLHmTTcrcmaSAkx6ilxCVrrxIW7CDBdUmJHlzNmBA2mDuQ2GX7IEbyEyNsiU0fFIlf8yQ2eK/ESqBUur12idnLndxurprrXjXstdfdbfb7e+B8xzP659FI8ozk9wtEotFo5qORPJ+Z719FCCFARETUpKe8DoCIiLoTEwgREbnCBEJERK4wgRARkSu7Kxf87ne/ww9/+EM8fvzYi3iIiMhndu3ahTfeeANf+tKXbMur7kCWl5eRTqe3LTCiZqyvr+PWrVteh9EV7t27h3v37nkdBvWAdDqN5eXlquVVdyDS22+/3dGAiNxYXFzE+Pg4f58OjI+PAwAWFhY8joS6naIoNZezDoSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECoR1renoa09PTXofhK4qi2B616LqOWCy2zZGRE7FYDIZh1HzNyXfbLCYQIo8YhtG2P+R2E0Kg1kDduq7j2rVrUFXVXJZOpxEIBKAoCsLhMHRdb3p/hmEgl8shkUggEAjUXS+bzZr7CgQCNfusyXUCgQCy2WzTsfg5Jl3XMT09bSaByn2dPn0awWCw5ndQ7zttiaiwsLAgaiwm8oVe+n1mMpmOfpaxsTExNjbW1HsA1I2pXC4LVVXF6uqquSwej4ulpSXzeSqVEqqqinw+39R+NU0TmqY13H80GhUAzG3n83kBQESj0ar9l8tlUS6XRSgUEvF4vKlY/BpTqVSyHftUKlW1LyGEWF1dNfdXS6PPUw8AsbCwUL28ckEv/YFS7+mV36c8GXdTAolGo0LTtKr1U6lU1TJVVZsL1sH+a71m3VexWBQAbCdZeUJvNqH5MSbrNraKLRQKVSWWrd7TSL0EwiIs2pF0XTeLXmo9z2azZpHE+vq6uY4sigCARCJhFtusra2Z265Vzly5LBqNmkUZ1uV+rZfRdR2RSAQnT560LY/H41hcXKxa/+DBg22PIRqNAgByuRwAmN/L66+/DgC4e/cuAODAgQPme/bv3w8AuH//ftvj2e6YTpw4YXsu6zo0Tatad3R0FJFIxFVxYlMqM0qvXOFRb2rX71Ne/cttWZ/LKz159RgKhYQQm1du1nVkkQQA8eDBAyHERlEDKq7y5LasyyqfC7FZbNIO7bwDkcVtxWKx4fsfPHjQ0hV/vf1LskhpdXVVpFIpUSqVzNfk91Brm27viPwaU7FYNPcrf3eVrwMQmUym5r6b/RsCi7CoF7Tz9+nkhO5knVrl3m631U7tTCDyZLUVTdM6VlwkyZOypmm2cv567231OPstJuvFSOXvTiqXy3Vfa2cCYREWUYuGh4cBAJFIxONIOufGjRtbrrO8vIzz58+bx6MTYrEYRkZGUC6XAQDBYLBus9Xtst0xDQ0NQQiBfD4PTdMQiUSQSCRs6/T19QHo/G+SCYSI2mLv3r0dTR7pdBqRSARnz55FX18fgsEgstmsOTKztWlxpVAo1HMxDQ8PIxgMAgAuX77c0rbcYgIhapNOnaS6QTqdrqrkbbeXX34ZwObV9eDgIIDNk6c8WVsrjmWl9rFjx3oypsOHD7e8jVYwgRC1SLbAOnfunMeRdI5sbVSvaObChQsdj6Hyal6etOXyM2fOAAAePnxorvPo0SPba70Wk/w+UqlUzddrtdBqJyYQ2pGsV4S6rtueyz9K68mysjmk7AFsGAaSySRUVbWdTOTdiEwuspknAITDYQD2q1M5NIhfm/HKK916CaRe3LFYDIqioFAobLkP67Zr7efKlSsANo+9PKZy+dDQEOLxOObn52EYBgzDwPz8POLxOIaGhro+pkAggFgsZt7BGIaBaDQKTdOqErhc5/jx41t+xpZU1qqzFRb5Wbt+n7C0Yqn1qLWOdVk+nzeb/sbj8apev8Vi0XxdNqVUVdXWzFO23tI0zVzm12a8smlyrc5sQtSPW9M0EQqFtmyy2uh7sFpaWjJbPIVCIVsveEk2OVZVtebr3RqT3IZ8RKPRut/H6uqqAGBrUlz5uZoBNuOlXuD179PNH59XOtETvV7v5q200uehU3o5Jk3T2BOdiPxjYmICKysrtuI4J3K5HKampjoUlTu9HFOhUEChUMDExEQbomqMCYTIocp6k52mr68Pc3NzmJmZcVR/AGz0Ddm3b1/HW2g1o5djWltbw+zsLObm5swK/U7a3Y6NyMozOf4LUS+STTTl/0W7h8b2ETk2V+VnHBgYQDKZxNzcnKM+H6dOnepIfK3o5Ziy2SyuX7+OgYGBqtc6MXVAWxKI1wzDQH9/v6s/aMMw8N577+Hdd99FNptFJpNpehv1vhgvTjCVx8JPsXW7nXDMnHzGvr4+XL16dRuioWY1+l468fttSwLx+s7jnXfecf1e2b7dyVAN9QghzBM3AJTL5W25fayl8lgIIaDrunn17GVsRNRbuv4OxDCMqnFgmiGTXysJBIDtpOzVCbresbDezjJ5EFG7tFyJ7td5FdrJbeeubjwWMgnJ909PT5sd3az7s86JbX3N+rnk8kAggOXl5arPaxgGwuGwLzvOEZEDle16m21n79d5FZrVaBtOO3dVbsNPx8LpMZL7LZVKVbHKzknyuZWqqmanpVKpZHaaE2KjoxUqOt/Jz5vP52turx6v+4F0Ezf9QIhqQSc7Ejo5iTlZx8t5FTq1Db8cC6efT/aIrfc+OQe0dWKhfD5vm9ZUztVcuX+ZhOU2683Z3AgTiHNMINQuXZFA2r2tVj5Du7bhl2PR7OcrFotmsrC+Tya2eDxuLotGo7aEYr3LqHy4icVK/j754IOP7X3USiBdX4lO7ZdIJJDNZhGNRqsmpBkeHkYoFMLly5fx/e9/HwDw/vvv2waGk/UwooPNXuV8C1TfW2+9BQB47bXXPI6Eup38W6/kywSyk+dVqLRdxyIcDuPmzZtIp9O4fPkyisWiLSlUxjQ7O4vbt2/j85//PC5dulRzvbW1tY7NVzA6OtqR7faSn/70pwB4rKhzfDWUyU6YV8Gp7TwWuVwOIyMjADYnyKmXPIDNu5CXX34ZiUSiaviFeDwOAEgmk+YQ2NYhy4moN7SlGa/1/36ZV6EZW43576QZb61t+OVYNBq3KZfL4Zvf/CaOHj1qe//6+rqtGXHlNuRdR60pO7/zne8A2Ohb09/fD0VRMDg4iNHR0R05hhRRz6pXSekUtqh4qbWOdVmn5lVoNX6rrZrxbnUMvDwWTmOT+6p8v2yVZa0kl1RVNZsZVyoWi0LTNAHA9n7rPt0MXc1WWM6xFRa1C+pUoitPXjQtLi5ifHy84+P+1BusbSfqxmNhGAb+8R//ETdv3tzW/W7X77MXjI+PAwAWFhY8joS6naIoWFhYwNjYmG25r+pAqHu8/fbbrJwl2uE8SSA7fV4Fq246FtPT07YhS/w4LDa1xjpcTb2hcNggwr9isVjdeeudfLfN8iSBVM6r0G6VB6reww86fSzaSbbMisfjno/A7BXDMDr62+n09p0SG52Mq5bruo5r167ZGk/I8d7kGG5uLoQMw0Aul0MikTDHhatFjqMmx1iTDU9qrRMIBMw+SW74MSZd120XcpX7On36NILBYM3voN532pLKShFWUpKfef37zGQyHd1/O7ff7jnRy+WyUFXVHLNNCCHi8bhYWloyn6dSKaGqqsjn803tVzZUabR/OTKC3Hat4X7k/svlsjmmnHXUhG6OqVQq2Y69HDKocu7z1dVVc3+1NPo89aBOJToTCHUVL3+f8gTaqf23e/vtTiDRaLSqNSIA2zhocpmbFnZb7b/Wa9Z9ycE/rSdZeUJvNqH5MSbrNraKLRQKVSWWrd7TSL0Ewkp02hEMw0A6nTZv/ROJhO023+1w+dsxHL/b6QTaSdd1RCIRnDx50rY8Ho9jcXGxav2DBw+2PQY5+Zvs/ySnDpDFqXfv3gUAHDhwwHzP/v37AQD3799vezzbHVNlh11Z16FpWtW6o6OjiEQiHa9XZQKhHSEYDOKjjz6CEAKlUgnZbBYTExPmH2GpVKp6T7FYtD231vuIJ+XJg4ODZrl2LpfD5OQkyuUyAODIkSNmEnG7fb+4d+8eAOC5556zLZ+cnLRNAy0/byeG4Ll69So0TcM3v/lN5HI53L17F6VSyZybfWVlBYB9FAU5mVor9Q5+jGl9fd1MXsFgsOp1+T3J761jKm9JWIRFfubm9ynnI7F2MpVzm1iLX1CnOMK6zMk6Qng7NYHUziIsWRewFU3TOlZcJMk5azRNs5Xz13tvq8fUbzFZ5wGq/I1J5XK57mtu9g0WYdFOdevWLQD2qX3l0C21il/aQV6BVo5m3K2cTPm8vLyM8+fPm5+9E2KxGEZGRsy7vGAwWLfZ6nbZ7piGhoYghEA+n4emaYhEIlVTWcupqzv++6vMKLwDIT9rx3w19ZbXWs/NOu3evlvtvANxEletSt5mNdqPbHUkr/AfPHgggM25aeo1QABqz6LZzTFJcn/NfGdufmPgHQjtVNYBJit1erj8nTI1QTqdrqrkbTc5UrS8upb9pi5fvgyg9vcsK7WPHTvWkzF1aroEp5hAqOfJ8XsePnxoLpNFDJ0ajqXXpiaQFbb1imYuXLjQ8RgqR36WJ225/MyZMwDs3/OjR49sr/VaTPL7SKVSNV+v1UKrnZhAqOedPXsWqqpiZmbGvBK8ffs2QqGQbTiWVqcO6NRw/H5oxiuvdOslkHoxxmIxKIqCQqGw5T62mlbhypUrADaPszx+cvnQ0BDi8Tjm5+dhGAYMw8D8/Dzi8bitFVS3xhQIBBCLxcw7GMMwEI1GoWlaVQKX6xw/fnzLz9iSyjIt1oGQn7n9fZZKJRGPx83y31Qq1bapA+Q2OzU1wVbTCdTTzjoQOTVAvXqOejHK6QC26lgo91v5qLS0tGS2eAqFQrZe8JLsza+qas3XuzUmuQ35iEajdb8P2cqw1vQW9T5HI6hTB8IEQl3Fj79PN3+Q26ETPdHr9W7eitue6Z3UyzFpmsae6ETkHxMTE1hZWbEVvTmRy+UwNTXVoajc6eWYCoUCCoUCJiYm2hBVY0wgRC3opuH4W9XX14e5uTnMzMw4qj8ANvqG7Nu3r+MttJrRyzGtra1hdnYWc3NzZoV+J+3u+B6IeljlcPzCR8OPtKLeLJkDAwNIJpOYm5tz1GHQj3PG9HJM2WwW169ft3WalToxTQATCFELeiVhSE4+T19fH65evboN0VCzGn0vnfitsgiLiIhcYQIhIiJXmECIiMgVJhAiInKlbiW6HAKbyE/kBDn8fW5NDmfBY0WdooiKqvn79+/jxRdf9CoeIiLyoXv37lWNrVWVQIhow/j4OABgYWHB40iI/Il1IERE5AoTCBERucIEQkRErjCBEBGRK0wgRETkChMIERG5wgRCRESuMIEQEZErTCBEROQKEwgREbnCBEJERK4wgRARkStMIERE5AoTCBERucIEQkRErjCBEBGRK0wgRETkChMIERG5wgRCRESuMIEQEZErTCBEROQKEwgREbnCBEJERK4wgRARkStMIERE5AoTCBERucIEQkRErjCBEBGRK0wgRETkChMIERG5wgRCRESuMIEQEZErTCBEROTKbq8DIPKDP/7xj7h58yYeP35sLvv1r38NAPjnf/5nc9muXbvwgx/8AJ/73Oe2PUYiv1GEEMLrIIi89i//8i946aWXAKBucvj4448BAPfu3cPx48e3LTYiv2ICIQLw+PFjDA4O4sMPP2y43rPPPotSqYRdu3ZtU2RE/sU6ECJsFE298sorePrpp+uu8/TTT+OVV15h8iB6ggmE6ImxsTF88skndV//5JNPMDY2to0REfkbi7CILIaGhvCb3/ym5mtf+cpXsL6+vs0REfkX70CILC5evIg9e/ZULd+zZw8uXrzoQURE/sU7ECKLX//613j++edrvvarX/0KX/va17Y5IiL/4h0IkcXXvvY1PP/881AUxVymKAqef/55Jg+iCkwgRBUuXryI3bs3+9ju3r2bxVdENbAIi6hCsVjEX//1X0P+aSiKgv/4j//AoUOHPI6MyF94B0JU4dChQzh+/DieeuopPPXUUzh+/DiTB1ENTCBENVy6dAmfffYZPvvsM1y6dMnrcIh8iUVYRDX8/ve/x1/91V8BAP77v/8bX/ziFz2OiMh/fJNA7t+/jxdffNHrMIiIfM1Pg3n6Zjj3999/HwDw9ttvexwJdcLPf/5zvPXWW131/f7f//0fFEXBM888s637feuttwAAr7322rbul/zv+9//Pt5//30mkHpGR0e9DoE64NNPPwXA79eJn/70pwB4rMj/WIlORESuMIEQEZErTCBEROQKEwgREbnCBEJERK4wgVDXmZ6exvT0tNdh+Jau64jFYl6HQTXEYjEYhuF1GG3DBELUJMMwbMO9+4mu67h27RpUVTWXpdNpBAIBKIqCcDgMXdeb3q5hGMjlckgkEggEAnXXy2az5r4CgQDS6XTddQKBALLZbNOx+DkmXdcxPT0NRVGgKErVvk6fPo1gMOjqO/Al4RMLCwvCR+FQm/XS95vJZDr6WcbGxsTY2FjT7yuXy0JVVbG6umoui8fjYmlpyXyeSqWEqqoin883tW1N04SmaQJA3c8ejUYFAHPb+XxeABDRaLRq/+VyWZTLZREKhUQ8Hm8qFr/GVCqVbMc+lUpV7UsIIVZXV839NQuAWFhYaPp9neKbv+heOsFQtV75fuVJ2o8JJBqNCk3TbMsAiFQqVbVMVVVXsTU6Wdd6zbqvYrEoANhOsvKE3mxC82NM1m1sFVsoFKpKLE74LYGwCIu6iq7rZpFMrefZbNYsqlhfXzfXkUUUAJBIJMzinLW1NXPbstihcjZC67JoNGoWcViXe10vo+s6IpEITp48aVsej8exuLhYtf7BgwfbHkM0GgUA5HI5ADCP/+uvvw4AuHv3LgDgwIED5nv2798PYGMsvE7YzphOnDhhey7rOjRNq1p3dHQUkUik+4uyvM5gUq9coVJt7fp+5dW/3Jb1ubwClFeVoVBICLF5FWhdRxZVABAPHjwQQmwUQaDiilFuy7qs8rkQm8Up7eDmDkQWqxWLxYbrPXjwoKUr/lqf3UoWKa2uropUKiVKpZL5mjzetbbp9o7IrzEVi0Vzv/L3Vfk6AJHJZJraLnx2B+KbMzYTSG9r5/fr5ITuZJ1a5eFut9VObhKIPFk5Wa9TxUWSPClrmmYr56/33laPp99isl50VP6+pHK5XPe1RvyWQFiERTvW8PAwACASiXgcSetu3Lix5TrLy8s4f/68+bk7IRaLYWRkBOVyGQAQDAY9b7a63TENDQ1BCIF8Pg9N0xCJRJBIJGzr9PX1Aej+3x4TCNEOsXfv3o4mj3Q6jUgkgrNnz6Kvrw/BYBDZbNYcwt/atLhSKBTquZiGh4cRDAYBAJcvX25pW37FBEI7XqdOXn6STqerKnnb7eWXXwaweXU9ODgIYPPkKU/W1opjWal97Nixnozp8OHDLW/Dz5hAaMeSLbDOnTvncSStk62N6hXNXLhwoeMxVF7Ny5O2XH7mzBkAwMOHD811Hj16ZHut12KS30cqlar5eq0WWt2ECYS6ivVKUdd123P5x2o9iVY2k5Q9gw3DQDKZhKqqtpOMvBuRyUU2/wSAcDgMwH7VKocM8boZr7zSrZdA6sUXi8WgKAoKhcKW+7Buu9Z+rly5AmDzGMtjJ5cPDQ0hHo9jfn4ehmHAMAzMz88jHo9jaGio62MKBAKIxWLmHYxhGIhGo9A0rSqBy3X8MrOga17X4ktshdXb2vX9wtK6pdaj1jrWZfl83mz6G4/Hq3oDF4tF83XZxFJVVVvzT9l6S9M0c5nXzXhlE+RandmEqB+fpmkiFApt2WS10fG2WlpaMls8hUIhWy94STY5VlW15uvdGpPchnxEo9G638fq6qoAYGtS7AR81grLN2dsJpDe5vX3W+/k4ket9ER307tZCNFSn4dO6eWYNE1jT3Qi8o+JiQmsrKzYit2cyOVymJqa6lBU7vRyTIVCAYVCARMTE22Iyls9l0Aqh7Ygqqw36VV9fX2Ym5vDzMyMo/oDYKNvyL59+zreQqsZvRzT2toaZmdnMTc3Z1bod7PdXgfQbteuXcPs7KzXYTSt0fDg0WgUhw8fxksvvdQTP7rtJptuyv8LITyMprMGBgaQTCYxNzfnqM/HqVOntiGq5vRyTNlsFtevX8fAwEBbtue1nrsDuXnzptchuCKEQKlUMp+Xy2WIjToqnD59GolEorfmEdhG8jjKR6/r6+vD1atXvQ6Darh69WrPJA+gBxNIN7P+sKx3GsPDw5ibmwOwUc7t9dAQRERADyQQwzCQTqfNIbytw3NbyTb7cr3l5WVz+VbDgUvy/YlEArquVxU71dsH0Ho/gYGBAVy5cgXZbBbvvPOOrz4bEe1Q3jUAs3PbzFNVVREKhcz2/HIWMOu2SqWS2ZZfiI124ajoE4AGw4ELsdFEUg6VXS6Xq0Y/bbQPIZz3E6iM3UqO4GmNyw+fzQmvm/F2E7fNeKn3wWfNeH3zF+3mBCM77ljH25cnWeu2ZFKxwpOOYPL/tV63LkNFpx/ZccvpPpxqlEBqvd4tn40JxDkmEKrHbwmkq1th/exnPwNgH7CsVislOSNbZbHMjRs3zJnJthIKhTA4OIhUKoWzZ89iYGDAViHbjn240W2f7datW02tvxPJ4kUeK/I9rzOY5OYKFQ4ng6m3XqPXK5c9ePDAViRU2Yt0q3041Wg78u7KeuXfLZ9Nfr988MFHaw/egXhkbW3N9fDKhw8fRiaTQaFQwOzsrDkRTGVzyVb2sZVf/OIXAFA173Wr+93OzyZ2QDPaVo2PjwMAFhYWPI6E/KZRfzEvdHUrrHg8DgBb9rqV6yWTSbMJrHUkVScURYFhGBgeHsbNmzeRz+dts4m1Yx+N6LqON998E6qq2jo19cJnI6Iu5fUtkOSmCEu2KFJV1WxFJFsIAZstjWSlcOWjWCzaXpMtuawV8bJyGdgoOpL7KRaLtqKeRvsQwlkrLOt+raPEyhZVqqpWjd7ph8/mBCvRnWMlOtUDnxVhdfUdyNDQEIrFIg4ePIhDhw4hHA7j61//OlRVRSqVwvXr1wFs9KEoFovm5C2hUAjFYhFDQ0O2YS76+/tt/wL2YTB+8IMf4NatW1AUBbdu3bIV8TTahxOKotj229/fD0VRoCgK7ty5g6mpKWQymaperN3w2YioNylC+KNQenFxEePj4ywj71H8fp1jHQjVoygKFhYWMDY25nUoALq8DoSIiLzDBEJERK4wgRD1GLaQ869YLNZTg6EygdCOYBhGR9vQd3r7Tum6jmvXrkFVVXOZHFBTURSEw2FXUwIYhoFcLodEItFwsrZsNmvuKxAIIJ1O110nEAggm802HYufY9J1HdPT02YDmMp9nT59uremZfC2EdgmNvPsbV5/v3LctG7YvttmvOVyWaiqag6cKYQQ8XhcLC0tmc9TqZRQVbWpgTCF2GyGjidNuGuJRqMC2BxkM5/PC8A+soHcf7lcFuVyWYRCIRGPx5uKxa8xlUol27GXY8hVjuywurpq7q9Z8FkzXt+csb0+wVBnefn9yhNrp/bf7u27TSDRaLSqrxEAcxRl6zJVVV3F1uhkXes1675kvy3rSVae0JtNaH6MybqNrWILhUJVicUJvyUQFmGRr1nne7HOVyLJ5dbio8pl0WjULJaQy3VdN4stACCRSJhFPNY5ZdxuH2h9Dphm6LqOSCRSNcxNPB43B8O0OnjwYNtjiEajAIBcLgdgc1BIOeDm3bt3AQAHDhww37N//34AwP3799sez3bHVDlfuqzrkP2nrEZHRxGJRLq+KIsJhHwtGAzio48+Mqf8zWaztlkZrdMAS8Vi0fbcOmKweDKt7eDgoFnencvlMDk5iXK5DAA4cuSImUTcbn+73bt3DwDw3HPP2ZZPTk4ik8mYz+XnCoVCbY/h6tWr0DQN3/zmN5HL5XD37l2USiVzbvaVlRUAsHVAlR1jW6l38GNM6+vrZvIKBoNVr8vvSX5vXcvT+x8LFmH1NjffrxyWxjp8y+rqalWxDOoUU1iXOVlHiNpl5G6375abIqzKScAardep4iIpFAqZw+NYy/nrvbfVY+e3mGSxmHzUKqqSQwo1W4wFFmEROSPnw7AO33L06FEAqFks0w7yytQ6mGQ3uHHjxpbrLC8v4/z58+Zn7IRYLIaRkRHzbi4YDHrebHW7YxoaGoIQAvl8HpqmIRKJIJFI2NaR8xZ12++sitcZTOIdSG/b7vle3KzT7u275eYOxMn+a1XyNqvRfmSrI3mF/+DBAwHAbNFUr6EBYJ9iuRdikuT+nPzOnADvQIickX0ZalU0dqIMfzu3v93S6XRVJW+7vfzyywA2r67lYJ2XL18GUPv7lJXax44d68mYOjU3kF8wgZBvyQHjHj58aC6TRQ+jo6Md2aesZD537lxHtt8pssK2XtHMhQsXOh6DtfMisHnSlsvPnDkDwP59Pnr0yPZar8Ukv49UKlXz9VottLoJEwj51tmzZ6GqKmZmZswrxNu3byMUCtkm1ZJ3C/LkL5tsAkA4HAZgv9KsHOZD9hY2DAPJZBKqqtpOPG63v53NeOWVbr0EUi+WWCwGRVG2nJStctu19nPlyhUAm8dTHie5fGhoCPF4HPPz8zAMA4ZhYH5+HvF43NYKqltjCgQCiMVi5h2MYRiIRqPQNK0qgct1jh8/vuVn9DWvy9Ak1oH0Nrffb6lUEvF43CwvTqVSVT14i8WiWZadyWSEEBtl26lUymzBJVtXaZpmm0gLTzqMyffH4/G2bd/JJGK1uKkDkZN+1avnqBeLpmkiFApt2bFQHqvKR6WlpSWzxVMoFLL1gpdkr31VVWu+3q0xyW3IRzQarft9yNaElRPEbQU+qwPxzRmbCaS3+fH7rZZeagwAACAASURBVHfC8VorPdHd9G4WQrjumd5JvRyTpmnsiU5E/jExMYGVlRVbEZsTuVwOU1NTHYrKnV6OqVAooFAoYGJiog1ReYsJhHYka6ubbh9OQurr68Pc3BxmZmYc1R8AG31D9u3b1/EWWs3o5ZjW1tYwOzuLubk5s0K/m+32OgAiL1jngx8cHOyZqXYHBgaQTCYxNzfnqMOgtTGCX/RyTNlsFtevX7d1ju1mTCC0I/VKwqilr68PV69e9ToMqqHXvhcWYRERkStMIERE5AoTCBERucIEQkRErviuEv373/++1yFQB8ihG/j9bk1OMsRjRX6nCJ80R/nd736HH/7wh3j8+LHXoRABAP7t3/4NAPD1r3/d40iINuzatQtvvPEGvvSlL3kdCgAfJRAivxkfHwcALCwseBwJkT+xDoSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyhQmEiIhcYQIhIiJXmECIiMgVJhAiInKFCYSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyhQmEiIhcYQIhIiJXmECIiMgVJhAiInKFCYSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyhQmEiIhcUYQQwusgiLz2/vvvY3h4GF/96lfx1FMb11UffvghAODZZ58FAHz22Wf4z//8T/z7v/87vvSlL3kWK5Ff7PY6ACI/ePz4Mf70pz/h17/+ddVr//Vf/2V7bhgGEwgRWIRFBAA4cuQIvvGNb0BRlLrrKIqCb3zjGzhy5Mg2RkbkX0wgRE9cunQJu3btqvv6rl27cOnSpW2MiMjfWAdC9MSjR4/w5S9/GfX+JBRFwW9/+1scOHBgmyMj8ifegRA9ceDAAXzrW98yK9GtnnrqKXzrW99i8iCyYAIhsrh48WLNehBFUXDx4kUPIiLyLxZhEVn8z//8DwYHB/GXv/zFtnz37t0olUrYt2+fR5ER+Q/vQIgs9u3bhzNnzmD37s0W7rt378aZM2eYPIgqMIEQVRgbG8Nnn31mPv/ss88wNjbmYURE/sQiLKIKf/zjH/HFL34Rf/7znwEAzzzzDH7/+9/j85//vMeREfkL70CIKnz+85/Hd7/7XezZswd79uzBd7/7XSYPohqYQIhqeOWVV/Dpp5/i008/xSuvvOJ1OES+5OlYWL/5zW+Qy+W8DIGopsePH5v//+ijj3Dr1i0PoyGq7cSJE/jKV77iXQDCQ6+++qoAwAcffPDBh4vHq6++6uUpXHh6B/Lxxx9jbGwMCwsLXoZBHlAUBQsLC2zdtIXFxUWMj4/XHV6Fdq7x8XF8/PHHnsbAOhAiInKFCYSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECoa42PT2N6elpr8PwLV3XEYvFvA6DaojFYjAMw+swWsIEQtQCwzBqTkDlB7qu49q1a1BV1VyWTqcRCASgKArC4TB0XW96u4ZhIJfLIZFIIBAI1F0vm82a+woEAkin03XXCQQCyGazTcfi55h0Xcf09DQURYGiKFX7On36NILBoKvvwDe87MU4NjYmxsbGvAyBPAJALCwseB1GyzKZjOjkn9HCwoKr7ZfLZaGqqlhdXTWXxeNxsbS0ZD5PpVJCVVWRz+eb2ramaULTNLM3dC3RaFQAMLedz+cFABGNRqv2Xy6XRblcFqFQSMTj8aZi8WtMpVLJduxTqVTVvoQQYnV11dxfs/xw/mQCIU/0QgKRJ2k/JpBoNCo0TbMtAyBSqVTVMlVVXcXW6GRd6zXrvorFogBgO8nKE3qzCc2PMVm3sVVsoVCoKrE44YfzJ4uwqGvpum4WydR6ns1mzaKK9fV1cx1ZRAEAiUTCLM5ZW1szty2LHazFU5XLotGoWcRhXe51vYyu64hEIjh58qRteTwex+LiYtX6Bw8ebHsM0WgUAMzBUuXxf/311wEAd+/eBQAcOHDAfM/+/fsBAPfv3297PNsd04kTJ2zPZV2HpmlV646OjiISiXRnUZaX2csPGZS8gTbcgcirf/kztj6XV4DyqjIUCpn7rVxHFlUAEA8ePBBCbBRBoOKKUW7LuqzyuRCbxSnt4OYORBarFYvFhus9ePCgpSv+Wp/dShYpra6uilQqJUqlkvmaPN61tun2jsivMRWLRXO/8vdV+ToAkclkmtquH86fTCDkiXYkELmdrU7oTtapVR7udlvt5CaByJOVk/U6VVwkyZOypmm2cv567231ePotJutFR+XvSyqXy3Vfa8QP508WYREBGB4eBgBEIhGPI2ndjRs3tlxneXkZ58+fNz93J8RiMYyMjKBcLgMAgsGg581WtzumoaEhCCGQz+ehaRoikQgSiYRtnb6+PgDd+dtjAiHagfbu3dvR5JFOpxGJRHD27Fn09fUhGAwim83i7bffBgBb0+JKoVCo52IaHh5GMBgEAFy+fLmlbfkJEwiRRadOXn6STqerKnnb7eWXXwaweXU9ODgIYPPkKU/W1opjWal97Nixnozp8OHDLW/Db5hAiACzBda5c+c8jqR1srVRvaKZCxcudDyGyqt5edKWy8+cOQMAePjwobnOo0ePbK/1Wkzy+0ilUjVfr9VCy++YQKhrWa8UdV23PZd/rNaTaGUzSdkz2DAMJJNJqKpqO8nIuxGZXGTzTwAIh8MA7FetcsgQr5vxyivdegmkXnyxWAyKoqBQKGy5D+u2a+3nypUrADaPsTx2cvnQ0BDi8Tjm5+dhGAYMw8D8/Dzi8TiGhoa6PqZAIIBYLGbewRiGgWg0Ck3TqhK4XOf48eNbfka/YQKhriWLIOT/rc/7+/tt/1auDwBHjx5FIBBAf38/hoaGkEwmba//6Ec/gqqqOHLkCLLZLE6cOAFVVZFKpXD9+nUAm30IfvzjH5tl3F578cUXAWxePTtVLpcRCoW2TH6KotiOa39/f9VwLqdOncLS0hJWVlagKArm5+extLSEU6dOmetMTk7i3Llz6O/vRzAYxOjoKCYnJ3sipsnJSUQiERw6dAiKomBubg5///d/b/5erOT3JL+3bqII4d1ky+Pj4wDAOdF3IC/nRJcnFg9/+o65nRNd3g1dvXq16X0GAgFkMpmm39dJvRzT9PQ0+vv7m/6u/HD+5B0IUQ+amJjAysqKrdjNiVwuh6mpqQ5F5U4vx1QoFFAoFDAxMdGGqLZf1yaQXC6HcDhsDiERDocbjsLZKyqH66DmVNab9Kq+vj7Mzc1hZmbGUf0BsNE3ZN++fR1vodWMXo5pbW0Ns7OzmJubMyv0u81urwNwY3l5Gd/+9rdRLBZx8+ZNhMNhzM7ONrUNwzDQ399vKxqotWw7OB0OXAiBa9eudfVn9VplvUkvf/6BgQEkk0nMzc056vNhrQvwi16OKZvN4vr16xgYGGjL9rzQlXcgt27dAgCzZcTNmzeb3sY777zjaNl2EEKYPWPlc+tjaWnJfK3bP6vXKo9tr+vr63NVD0Kdd/Xq1a5OHkCXJpBmr8ArGYZRNZxArWXbqdEtbCtXPH78rETUG7oqgdQbXrsWeZKU60xPT5tl3rWG4a43NDew2cZfDg2+vLxsLt9q+HCgtX4BTloM+emzEtEOsq1DN1ZwO5okHIySKkfcLJVKVUN6O92GEBvDequqak7Es7S0ZA6B7WT4cCGcD+9duX+5ra3W89NndQo9MKHUdnA7oRT1Pj+MxtuzCUTTtIYnUacnVTkVZeV6MiE43U4zn6vyUW89qVs/KxPI1phAqB4/JJCu7EhYq1inXlHP+vo6bt26ZQ6VLF93uo1AIGAW91QSQjQVS7Ofa319HYcOHaraTq981hdffNE2RARVW19fx7179zA6Oup1KOQz9+7dw9/+7d+yI2GnJBIJ/MM//EPDYZq3Ik+ooqL1znbk3WZOrt3+WYmo+3RlPxAn0uk0Ll++jGKx2Jar3LW1NU+GY3Zy8u7Wz/raa695MpRJN5FDmcg5K4gkWYLjpZ69A5Fj/7d6Qo3H4wCAZDJpjvBpHXnVD3bSZyUi/+i6BGIdlkEOs11reApZlLO+vm6uV+t16wmy1rLvfOc7ADamCZUjfA4ODmJ0dNTx8OFOmvFuNRR15Tb9+lmJaOfoqgSiKApeeOEF8/mRI0fMk5wk/y+HTU4kEujv74emaQiFQvjzn/9se906DHetZQMDAygWi+ZkL6FQyCwqanb48Eafa6uhqGttsxs/KxH1jq5shUXdz8vh3LuJ2+Hcqff54fzZVXcgRETkH0wgROQIG1RsTNTVqI5yp2ECoR3HMAzHQ+j7cfte0HUd165ds/UzkmOjyfl43DSk0HXdNo6bnK9cksey1sO67vr6ujk/UDgcNsdwq5TNZhEIBBp2mm20zunTpxEMBtlo5AkmENpxOj2Ufa8NlW8YBiYmJnDp0iWzf1AikcDAwAAymQyEEBgZGcHExITjyaus2wU2+juVSiUsLi7aWiy+9957dd8vR6k2DAOFQgE3b95EuVzGyMgIvv3tb1ed/NPpNBKJBJLJJJLJJH72s59VjUq91TrDw8OYmprCxMQE70SA7hxMkbofPBoLq1wumwNDdsP2/TAWVjQarRoMFIA56KZ1maqqjrcrx14rl8vmsnw+LwCIpaUlc51isWh7X6lUssWTyWSqto06A5PKgUCt+8rn847XkUKhkIhGo44/ayf44fzJOxDqGoZhIJ1Om0UYiUTCVpRgLd6ot6zWUPa6rpvFFgDMIpVwOGzrV+N2+0BrQ/p7Sdd1RCIRnDx50rY8Ho9jcXGxav2DBw863rZ8v3UunK9+9asANieNO3XqVFUH2eXlZZw/f958Xm/4nlAoZP7/7t27AIADBw6Yy/bv3w8AuH//vuN1pNHRUUQikR1flMUEQl0jGAzio48+Mos7stmsrSihVCpVvadYLNqey/4vwOaYX4ODg2Z5dy6Xw+TkpDlD5JEjR8wk4nb73ezevXsAgOeee862fHJyEplMxnwuj5H1pL2VWnUQMpnISeNqzdi3srLScIpe+Xs4d+6c7T2AfbQGuW0Zh5N1JHk85PHZqZhAqCssLy8jm82aveUHBgYwNTWFbDaL27dvm8sqORnexXqSP3HiBICNE5k8GcqTh9vtAxuJxZpcuoW88t7qcyaTSeTzeUdzr0vy+Frv8rZSKBQwMjLScJ1f/OIXUFUVL730krms0Sym8vt1so4kE10zsfciJhDqCrJIw3oSP3r0KADULEppB3kylMPj70Q3btzYch1ZpNRM8gCAS5cuAQDeeOMN865BVsJHo9Ga7/nJT36y5RTPb775JqamphpOE90que2d/NsAmECoS9S6OpR/xPWaY9L22Lt3b9PJA9i421taWsIHH3yA/v5+JBIJfPjhhwA2mstWkvUNte4EpXQ6DVVVzTtJqdE0B/JOyMk6ZMcEQl3BOvhjpU7/cfPkUV86na46WTfj1KlTZlPgyclJ/PKXv4SmaTUTUmXleaVCoYBf/epXmJycrHqt1u9nfX0dAHDs2DHH65AdEwh1BTlm1sOHD81lstijU7P1yfJta2XsTiOLkur1ebhw4ULb9pVOp7GyslK3WKhR5bmu67hz546tnqlQKCAcDgMAzpw5A8D++3n06JHtNSfrVJIDj+5UTCDUFc6ePQtVVTEzM2NeId6+fRuhUMhWJl5ZMZvL5czX5Mmk1lD2kuzdbBgGkskkVFW1FW243X63NuOVHQfrJZB6nysWi0FRlC07FspOgOFwGB988AEymUzNuotGlee6rmNiYgKRSMTWrPqFF14wk//Q0BDi8Tjm5+dhGAYMw8D8/Dzi8bjZQMDJOpK8Mzl+/HjDz9fzPOyD4ouOMOQNuOhIWCqVRDweNzuJpVIpWyc0ITY6g8mOfLKDmaqqIpVKiVKpJITY7BymaZq5TG4zn8+b74/H423bvqZpVZ3xnPC6I2GpVKrqXGdV73NpmiZCoVDDjoXymMfj8aqOerW2J49lpVAoZG6r8vHgwQPbuplMxuzwKDsrVnKyzurqqgBQN6bt4IfzJ4dzJ0/4bTh32eHPwz+HmvwwnLu8i7p69WrT7w0EArb+Ir1ienoa/f39ro5Ju/jh/MkiLCJqaGJiAisrK7biOidyuRympqY6FJV3CoUCCoWCOY7XTsYEQjterWmCaVNfXx/m5uYwMzPjeLDE5eVl7Nu3r6UWWn60traG2dlZzM3NdbSfSbdgAqEdr9Y0wWQ3MDCAZDKJO3fuOFr/1KlTZgV8L8lms7h+/XrDvig7yW6vAyDymt/qPfyqr6/P0zJ/P9jpn78S70CIiMgVJhAiInKFCYSIiFxhAiEiIleYQIiIyB0vu8G/+uqrdYcg4IMPPvjgo/Hj1Vdf9fIU7u1QJr/5zW+a7t1KtF3eeustAMBrr73mcSREtZ04cQJf+cpXPNu/pwmEyM/8MNYQkZ+xDoSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyhQmEiIhcYQIhIiJXmECIiMgVJhAiInKFCYSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyhQmEiIhcYQIhIiJXmECIiMgVJhAiInKFCYSIiFxhAiEiIleYQIiIyBUmECIicoUJhIiIXGECISIiV5hAiIjIFSYQIiJyZbfXARD5RbFYxOPHj83n//u//wsAePjwobls165dOHTo0LbHRuRHihBCeB0Ekdd+/vOf4+/+7u8crfvLX/4SL7zwQocjIvI/JhAiAOVyGV/4whccrfuHP/wB/f39HY6IyP9YB0IEoL+/H4FAALt31y/V3b17NwKBAJMH0RNMIERPBINBWx1IpcePHyMYDG5jRET+xiIsoif+/Oc/49lnn8Wf/vSnmq/v3bsXH374IZ555pltjozIn3gHQvTEM888g+9973vYs2dP1Wt79uzB9773PSYPIgsmECKL8fFxfPrpp1XLP/30U4yPj3sQEZF/sQiLyOIvf/kLBgYG8Ic//MG2/Atf+AJ0XW9YyU600/AOhMhi9+7dGBsbw9NPP20ue/rppzE2NsbkQVSBCYSowoULF/DJJ5+Yzz/55BNcuHDBw4iI/IlFWEQVhBD48pe/jEePHgEADhw4gN/+9rdQFMXjyIj8hXcgRBUURcHFixexZ88e7NmzBxcvXmTyIKqBdyBENbz77rv4xje+AQD413/9V/zN3/yNxxER+U/X1QpOTU3h/fff9zoM2kFef/11r0OgHeC5557DzMyM12E0pevuQGRRwujoqMeRkJ+tr6/j3r17Lf1Ofv/730NRFDz77LNtjMx/7t27BwB48cUXPY5k57p16xaAjfq3btKVCWRhYQFjY2Neh0I+tri4iPHx8a77g/SC7CC5sLDgcSQ7V7f+XlmJTkRErjCBEBGRK0wgRETkChMIERG5wgRCRESuMIEQbWF6ehrT09Neh+Fbuq4jFot5HYanYrEYDMPwOoxtxwRC5HOGYfh2KBVd13Ht2jWoqmouS6fTCAQCUBQF4XAYuq672m4ikYCiKFAUBel02va6PCa1HtZ119fXEQ6HzViWl5dr7i+bzSIQCCAQCCCbzTa9zunTpxEMBl191m7GBEK0hddff93T3ujvvPOOZ/tuxDAMTExM4NKlSzh8+DAAIJFIYGBgAJlMBkIIjIyMYGJiAoVCoentAhsd60qlEhYXF213ge+9917d9586dcrcTqFQwM2bN1EulzEyMoJvf/vbVSf/dDqNRCKBZDKJZDKJn/3sZ0gkEk2tMzw8jKmpKUxMTOysOxHRZQCIhYUFr8Mgn1tYWBBd+POuUi6XhaqqHf0sY2NjYmxsrOn3RaNRoWmabRkAkUqlqpapqup4u6lUSgAQ5XLZXJbP5wUAsbS0ZK5TLBZt7yuVSrZ4MplM1bYB2I5lsVgUAMTq6mrVvvL5vON1pFAoJKLRqOPPKnXr75V3IEQN6LpuFsnUep7NZqEoCgKBANbX1811ZHEHALMoJhwOY21tzdy2tdil3rJoNGpeMVuXe10vo+s6IpEITp48aVsej8exuLhYtf7Bgwcdb1u+v6+vz1z21a9+FcDmkB+nTp3C0NCQ7X3Ly8s4f/68+dxarGYVCoXM/9+9exfAxpD90v79+wEA9+/fd7yONDo6ikgksnOKsrzOYM0C70DIgXZd0cmrf7kt63N5RSqvUEOhkBBi8yrXuk65XBahUEgAEA8ePBBCbFwxo84VsXVZ5XMhhNA0rerq3y03dyCZTEYAqLoLqPTgwYOaV+qN1Pq8jZZL8vjXUy6XBQDbnYn8TmrtS941OVlHkt9frbufRrr1DqTrImYCISfa+Qfp5ITuZB1Z7GEt4nC7rXZyk0A0TXMUk6ZpTSUPIURVopUaHYd8Pl9VdFZpaWlJqKpqKxpzkqyaSWgySTVbjNWtCYRFWETbZHh4GAAQiUQ8jqR1N27c2HIdWaQkP7dTly5dAgC88cYbZoW0rISPRqM13/OTn/zErDyv580338TU1JStaKzd5LZ74Tt2ggmEiDpi7969TScPADhx4gSWlpbwwQcfoL+/H4lEAh9++CGAjeaylWR9w8DAQN1tptNpqKqKEydO2JbXqycBNutKnKyzUzGBEG2znXDSSafTVSfrZpw6dcpsCjw5OYlf/vKX0DStZkKqrDyvVCgU8Ktf/QqTk5NVr8nkYK30lo0hjh075nidnYoJhGibyBZY586d8ziS1smipHp9Hi5cuNC2faXTaaysrNQtFlpZWal7p6PrOu7cuWPrx1MoFBAOhwEAZ86cAQA8fPjQfP3Ro0e215ysU0nTtK0/WA9gAiFqwHrVqeu67bk8eVpPopXNN2WvaMMwkEwmoaqqrUhE3o3I5JLL5czX5EnOegUshwzxuhmv7DhYL4HUiy8Wi0FRlC07FspOgOFwGB988AEymUzNuotCoYCRkZGa29B1HRMTE4hEIrbm0S+88IKZxIeGhhCPxzE/Pw/DMGAYBubn5xGPx81mwk7WkeSdyfHjxxt+vl7BBELUwODgoO3/1uf9/f22fyvXB4CjR48iEAigv78fQ0NDSCaTttd/9KMfQVVVHDlyBNlsFidOnICqqkilUrh+/TqAzTnZf/zjHyMYDLb3A7okp7+VV+JOlctlhEKhhslPURT09/fj/v37CIVCuHr1at11G1WeX7t2re6wJEeOHDH/Pzk5iXPnzqG/vx/BYBCjo6NVxV1O1gE2j8dOmR6YU9pST/J6ilDZ4a8b/rzcTmkr74YaneDrCQQCyGQyTb/P76anp9Hf39/0MfH69+oW70CIyJWJiQmsrKzYit2cyOVymJqa6lBU3ikUCigUCuY4XjsBEwhRm1XWm/Sqvr4+zM3NYWZmxvFgicvLy9i3b19LLbT8aG1tDbOzs5ibm+toPxO/2ZEJpHI8I6J2qqw36WUDAwNIJpO4c+eOo/VPnTplVsD3kmw2i+vXrzfsi9KLdnsdgBeuXbuG2dlZr8NwzTAMvPfee3j33XeRzWZdlSU3ml8iGo3i8OHDeOmll3bU1VS7dFs5dqv6+vpc1YP0kp36+XfkHcjNmze9DqEl0WgU/+///T9cvny5biuTrYgn8yxI5XIZYmNsNJw+fRqJRGJHTpBDRM7tyATS7do1wZH1dtt6pzE8PIy5uTkA2HkT5BCRYzsigRiGgXQ6bc7bYJ2TwUp21JLryekvncwBIcn3JxIJ6LpeVVRUbx/t1mpHs4GBAVy5cgXZbLZqRrxeOk5E1AKvhgF2Cy6Gc1dVVYRCIXMYZznjmfXjl0oloaqqOST00tKSOY+BkzkghNiYoU3Oj1Aul6uGvG60DzcqP4OV0/kiGm1DDk1t/Yzdcpy6dXhsL7idkZDap1t/r10XcbMJRE58Y51bQJ4YrV+YTCqV+5In4Von2splAESpVDKfywmDnO6jWY1O/u3aRrcep279g/QCE4j3uvX32nURN5tAGs0mZl1uvXqufNRav9Yyua9UKmWbtMbpPprlRQLpluMk/yD54KObHt2m55vxOm2uK1sziRaaYP7whz/EBx98gJdffhnARmspa/O+duxjO8nKc+vIot12nN5+++2Wt9Hr3nrrLQDAa6+95nEkO9fPf/5z83voJj2fQJq1trbmuqPT4cOHkclkUCgUMDs7aw4/XdlGvJV9bKdf/OIXAICTJ09WvdYtx2l0dLSl9+8EP/3pTwHwWHnp008/9ToEV3q+FVY8HgeALYdakOslk0nzyts6fLYTiqLAMAwMDw/j5s2byOfztjkM2rGP7aLrOt58802oqmob7ZTHiYhM3pagNQ9org5EtgJSVdVs+SNb9QCbrYNkRW7lo1gs2l6TZfbWinhZIQxsVPTK/RSLRRGNRs1YGu2jWdb916pHcNIKq942ZIsqVVVtld3ddJy6tVLSC6xE9163/l57/g5kaGgIxWIRBw8exKFDhxAOh/H1r3+9as6FgYEBFItFs7w/FAqhWCxiaGioqTkgfvCDH+DWrVtQFAW3bt2yFcs02kcz5HwJ1pgaDU3SzDYURcGdO3cwNTWFTCZTNbZPNx0nIuoszgdCPalb51fwgtv5QKh9uvX32vN3IERE1BlMIETkC140lIjFYhzrrQVMID4h6x+2elB3MAyjo99Xp7e/3XRdx7Vr16CqqrlMjqumKArC4bCrkaENw0Aul0Mikag5/8/p06c56nQLmEB8QjwZSn2rB3WHygEou23728kwDExMTODSpUtmv59EIoGBgQFkMhkIITAyMoKJiQnHMx9KW019MDw8jKmpKY467RITCFGbGYaBRCLRtdvfbnNzcxgeHrZNc3v58mXbXcGFCxeQzWabHmHaydQHJ06cwMGDB80pDMg5JhAiC+vQ/9bh5qVaxYmVy6LRqHm1K5fruo5sNmsWoyQSCbNoxjq9VUJ3EwAAA31JREFUgNvtA60P4e8FXdcRiUSqRjuIx+NYXFysWv/gwYMdiWN0dBSRSIRFWU1iAiGyCAaD+Oijj8wZG7PZrK14wzqLo1QsFm3PrVe8suhxcHAQgUAA2WwWuVwOk5OTKJfLAIAjR46YScTt9rvVvXv3AADPPfecbfnk5KRtqmZ5fEKhUEfikPuX8ZAzTCBETywvLyObzeI73/kOgI0OjVNTU8hms7h9+7a5rJKTDo7Wk7wsqunr6zNPiPKOwu32gfbNVLmd7t+/D2Drz5hMJpHP5zE8PNyROOSMnPUmm6PamECInrh16xYA+0n86NGjAFCzOKUd5AnROhbYTnLjxo0t11leXsb58+c7ljyAzQSyU78Ht5hAiJ6oNfS/PLHUasFD22Pv3r0dTR7kHhMI0ROyD0KtitROlb1v1/a7VTqdtrXOIn9hAiF6Qo6v9vDhQ3OZrDzv1FwZssz93LlzHdm+30WjUQCo2wfjwoUL2xmObfI02hoTCNETZ8+ehaqqmJmZMe9Cbt++jVAoZJsTRd4tyJN/LpczXwuHwwDsdzOVw3Ok02kAGyfNZDIJVVVtPbDdbr8bm/HKjoP1Eki9zxSLxaAoiqOOhdZt19vP+vo6AOD48eNbbo82MYEQPdHX14e5uTmoqorBwUGzf8U//dM/2db70Y9+BFVVceTIEWSzWZw4caJqegDZGurHP/4xgsGg7f1Hjx5FIBBAf38/hoaGkEwm27r9bvLiiy8CAB49etTU+8rlMkKh0JYJ0+nUB3L/Mh5yhsO5U0/y4/DY8sTlp5gA74dzl3dQlVMaOxEIBGz9Rdyanp5Gf3+/qxjawY+/Vyd4B0JEnpqYmMDKyoqtqM6JXC6HqamplvdfKBRQKBQwMTHR8rZ2GiYQom1gbdnF4TLsZNHhzMyM48ESl5eXsW/fvpZbaK2trWF2dhZzc3Nmk21yjgmEaBtYp/O1/p82DAwMIJlM4s6dO47WP3XqlFkB34psNovr16/XHAGAtrbb6wCIdoJuK9v2Ql9f37bXQXhV59EreAdCRESuMIEQEZErTCBEROQKEwgREbnSlZXot27dwp49e7wOg3xMTgwkh2in+uQwHjxW3unWY991PdE/97nP4ZNPPvE6DCKitnr66afx8ccfex1GU7ougRARkT+wDoSIiFxhAiEiIleYQIiIyBUmECIicuX/A108XhKv9qghAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(learner, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68F3ft43tV-"
   },
   "source": [
    "## Train the learner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_addons.optimizers import RectifiedAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val-loss', \n",
    "    min_delta=1e-9, \n",
    "    patience=6, \n",
    "    verbose=1, \n",
    "    restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_sp = f\"experiments/{learner.name}.hdf5\"\n",
    "ms =  tf.keras.callbacks.ModelCheckpoint(filepath=learner_sp, \n",
    "                                            verbose=1, \n",
    "                                            save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from livelossplot import PlotLossesKeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "-T-a9YhO3tV-"
   },
   "outputs": [],
   "source": [
    "epochs = int(1e9)\n",
    "loss_fn = tf.losses.binary_crossentropy\n",
    "metrics=[tf.metrics.BinaryAccuracy()]\n",
    "\n",
    "callbacks = [es, ms, PlotLossesKeras()]\n",
    "\n",
    "learner.compile(\n",
    "    optimizer=RectifiedAdam(),\n",
    "    loss=loss_fn,\n",
    "    metrics=metrics\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000000000\n",
      " 85/100 [========================>.....] - ETA: 3s - loss: 0.7271 - binary_accuracy: 0.5288"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-29113d219c90>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m learner.fit(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\GPUEnv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(\n",
    "    x=train_ds, \n",
    "    epochs=epochs, \n",
    "    steps_per_epoch=100,\n",
    "    callbacks=callbacks, \n",
    "    validation_data=val_ds, \n",
    "    validation_steps=10,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D-1apOpM3tWA"
   },
   "source": [
    "## Evaluate the learner on training, validation and holdout dataset\n",
    "\n",
    "Note that data augmentation and dropout are inactive at inference time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = tf.keras.models.load_model(filepath=learner_sp, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.losses.binary_crossentropy\n",
    "metrics=[tf.metrics.Accuracy()]\n",
    "\n",
    "callbacks = [es, ms, PlotLossesKeras()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mertics_dict = dict(zip(list(map(lambda m: str(m.__class__.__name__), metrics)), metrics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds2itr(ds):\n",
    "    while True:\n",
    "        try:\n",
    "            for data in ds:\n",
    "                yield data\n",
    "        except StopIteration as e:\n",
    "            pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(train_ds)\n",
    "train_loss_scores = {}\n",
    "train_loss_score = []\n",
    "for ep in tqdm(range(eval_epoch)):\n",
    "    batch = next(ds)\n",
    "    train_loss_value = loss_fn(batch[1], learner.predict(batch[0]) )\n",
    "    train_loss_score += [train_loss_value]\n",
    "train_loss_scores = {loss_fn.__name__: train_loss_score}   \n",
    "\n",
    "train_loss_scores = {k: {'min': \n",
    "                          tf.math.reduce_min([*val][0], axis=0).numpy(), \n",
    "                          'max':\n",
    "                          tf.math.reduce_max([*val][0], axis=0).numpy(), \n",
    "                          'std': \n",
    "                          tf.math.reduce_std([*val][0], axis=0).numpy(), \n",
    "                          'mean': \n",
    "                          tf.math.reduce_mean([*val][0], axis=0).numpy() } for k, val in train_loss_scores.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)\n",
    "val_loss_scores = {}\n",
    "val_loss_score = []\n",
    "for ep in tqdm(range(eval_epoch)):\n",
    "    batch = next(ds)\n",
    "    val_loss_value = loss_fn(batch[1], learner.predict(batch[0]) )\n",
    "    val_loss_score += [val_loss_value]\n",
    "val_loss_scores = {loss_fn.__name__: val_loss_score}   \n",
    "\n",
    "val_loss_scores = {k: {'min': \n",
    "                          tf.math.reduce_min([*val][0], axis=0).numpy(), \n",
    "                          'max':\n",
    "                          tf.math.reduce_max([*val][0], axis=0).numpy(), \n",
    "                          'std': \n",
    "                          tf.math.reduce_std([*val][0], axis=0).numpy(), \n",
    "                          'mean': \n",
    "                          tf.math.reduce_mean([*val][0], axis=0).numpy() } for k, val in val_loss_scores.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(holdout_ds)\n",
    "holdout_loss_scores = {}\n",
    "holdout_loss_score = []\n",
    "for ep in tqdm(range(eval_epoch)):\n",
    "    batch = next(ds)\n",
    "    holdout_loss_value = loss_fn(batch[1], learner.predict(batch[0]) )\n",
    "    holdout_loss_score += [holdout_loss_value]\n",
    "holdout_loss_scores = {loss_fn.__name__: holdout_loss_score}   \n",
    "\n",
    "holdout_loss_scores = {k: {'min': \n",
    "                          tf.math.reduce_min([*val][0], axis=0).numpy(), \n",
    "                          'max':\n",
    "                          tf.math.reduce_max([*val][0], axis=0).numpy(), \n",
    "                          'std': \n",
    "                          tf.math.reduce_std([*val][0], axis=0).numpy(), \n",
    "                          'mean': \n",
    "                          tf.math.reduce_mean([*val][0], axis=0).numpy() } for k, val in holdout_loss_scores.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train loss', train_loss_scores)\n",
    "print('val loss',val_loss_scores)\n",
    "print('holdout loss', holdout_loss_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decision = lambda x: 1 if x > 0.5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(train_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    train_metric_scores = {}\n",
    "    train_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        train_metric_value = metric_fn(batch[1], pred)\n",
    "        train_metric_score += [train_metric_value]\n",
    "    train_metric_scores = {metric: train_metric_score}   \n",
    "\n",
    "    train_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in train_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(train_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    val_metric_scores = {}\n",
    "    val_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        val_metric_value = metric_fn(batch[1], pred)\n",
    "        val_metric_score += [val_metric_value]\n",
    "    val_metric_scores = {metric: val_metric_score}   \n",
    "\n",
    "    val_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in val_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(val_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(holdout_ds)\n",
    "mertics_score = {}\n",
    "for metric, metric_fn in mertics_dict.items():\n",
    "    holdout_metric_scores = {}\n",
    "    holdout_metric_score = []\n",
    "    for ep in tqdm(range(eval_epoch)):\n",
    "        batch = next(ds)\n",
    "        pred = np.array([[decision(p)] for p in learner.predict(batch[0])])\n",
    "        holdout_metric_value = metric_fn(batch[1], pred)\n",
    "        holdout_metric_score += [holdout_metric_value]\n",
    "    holdout_metric_scores = {metric: holdout_metric_score}   \n",
    "\n",
    "    holdout_metric_scores = {k: {'min': \n",
    "                              tf.math.reduce_min([*val], axis=0).numpy(), \n",
    "                              'max':\n",
    "                              tf.math.reduce_max([*val], axis=0).numpy(), \n",
    "                              'std': \n",
    "                              tf.math.reduce_std([*val], axis=0).numpy(), \n",
    "                              'mean': \n",
    "                              tf.math.reduce_mean([*val], axis=0).numpy() } for k, val in holdout_metric_scores.items()} \n",
    "   \n",
    "    mertics_score.update(holdout_metric_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train metric', train_metric_scores)\n",
    "print('val metric',val_metric_scores)\n",
    "print('holdout metric', holdout_metric_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = tf.keras.models.load_model(filepath=learner_sp, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.layers[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Reshape(image_size)(learner.layers[-3].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = tf.keras.Model(inputs=learner.inputs, outputs=[x])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds2itr(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(ds)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((images[0].numpy()* 255.0).astype(np.uint8), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model2.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray((predictions[0] * 255.0).astype(np.uint8), mode='RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.reporting.ploting import plot_and_save_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_generated(images.numpy(), epoch=999, path='.', gray=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_generated( [Image.fromarray((img * 255.0).astype(np.uint8), mode='RGB') for img in predictions], epoch=999, path='.', gray=False, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_from_scratch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
